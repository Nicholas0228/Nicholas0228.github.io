---
permalink: /
title: "Xiaoyu (Nicholas) Wu 吴晓宇"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
My research interests include copyright protection and authentication with/against AI personalization, as well as privacy and security topics like adversarial attacks and defenses, data extraction, and membership inference attacks. My previous research experience mainly focuses on diffusion models, but I am also highly interested in different forms of generative models, such as LLMs.

I co-founded a volunteer interest group that addresses copyright issues related to generative models for images. We develop software and provide technical services for AI copyright lawsuits as volunteers. E-mail us if you're interested or need assistance!

***I am looking for a PhD position in Fall 2025!!***

## News

**Oct 09, 2024**: New work on data extraction for personalized diffusion models is now available on [arXiv](https://arxiv.org/abs/2410.03039). We successfully extracted high-quality training data using publicly available checkpoints on HuggingFace.

**May 30, 2024**: Published new findings on mitigating quality degradation during few-shot fine-tuning of diffusion models [arXiv](https://arxiv.org/abs/2405.19931). We identified a phenomenon called the "corruption stage," where image quality abnormally degrades, and improved performance using BNNs.

**Feb 02, 2024**: Our paper on copyright authentication for diffusion models has been accepted at CVPR 2024. Read the full paper on [CVF](https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_CGI-DM_Digital_Copyright_Authentication_for_Diffusion_Models_via_Contrasting_Gradient_CVPR_2024_paper.pdf). The code is available through our project *Revelio* on [GitHub](https://github.com/Nicholas0228/Revelio).

**Dec 15, 2023**: [Mist-v2](https://github.com/psyker-team/mist-v2) has been released! It provides enhanced protection against LoRA-based attacks. More details are available on the [homepage](https://psyker-team.github.io/index_en.html).

**May 10, 2023**: Our adversarial watermarking project, *Mist*, is now [open-source on GitHub](https://github.com/psyker-team/mist). Add watermarks to protect your artwork from unauthorized use!
